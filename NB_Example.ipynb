{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 1.0 (January 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run Tutorial1_Appendix.ipynb #Fetch some functions from the Appendix, such as get_genome_pair(student_id)\n",
    "my_genomes = get_genome_pair(\"B00672276\")\n",
    "print(my_genomes) # Print the genome IDs out as text below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"tutorial1_appendix_data/\" + my_genomes[0] + \"_subset.faa\", 'r') as genome_file:\n",
    "    print(genome_file.readline())\n",
    "    \n",
    "with open(\"tutorial1_appendix_data/\" + my_genomes[1] + \"_subset.faa\", 'r') as genome_file:\n",
    "    print(genome_file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(sequence, w):\n",
    "    count_dict = {}\n",
    "    for i in range(0, len(sequence) - w + 1):\n",
    "        word = sequence[i:i+w]\n",
    "        if word not in count_dict:\n",
    "            count_dict[word] = 1\n",
    "        else:\n",
    "            count_dict[word] += 1\n",
    "    return count_dict\n",
    "\n",
    "def index_fasta_file(fasta_filename, w = 4):\n",
    "    word_dict = {} # Stores each of the protein data points\n",
    "    sequence = \"\" # Start building the sequence, since it can be spread across multiple lines\n",
    "    row = 0 # Keep track of which sequence we have processed\n",
    "    with open(fasta_filename, 'r') as fasta_file:\n",
    "        for line in fasta_file: # Loop through the file line-by-line\n",
    "            if line[0] == \">\": # Every time it hits a label, we are done processing the last sequence\n",
    "                if len(sequence) >= w:\n",
    "                    # Count the words using the function above\n",
    "                    count_dict = count_words(sequence, w)\n",
    "                    # For each word, we want to add it to our matrix that we are building\n",
    "                    for word, count in count_dict.items():\n",
    "                        # If we've seen the word before, append to the existing count list\n",
    "                        if word in word_dict:\n",
    "                            word_dict[word] = word_dict[word].append(\n",
    "                                                              pd.Series([count],index=[row])\n",
    "                                                                    )\n",
    "                        # If it's a new word, start a counting list\n",
    "                        else:\n",
    "                            word_dict[word] = pd.Series([count],index=[row])\n",
    "                    row += 1\n",
    "                sequence = \"\"\n",
    "            else: # We have a protein sequence, not a label\n",
    "                sequence += line.strip() # Build the full sequence string, removing trailing whitespace with strip() \n",
    "    return pd.DataFrame(word_dict).fillna(0) # Return the counts as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_size = 1 # Word size: Change this to change the word length for each genome\n",
    "\n",
    "count_matrix_1 = index_fasta_file(\"tutorial1_appendix_data/\" + my_genomes[0] + \"_subset.faa\", word_size)\n",
    "count_matrix_2 = index_fasta_file(\"tutorial1_appendix_data/\" + my_genomes[1] + \"_subset.faa\", word_size)\n",
    "\n",
    "genome_labels = [0]*count_matrix_1.shape[0] + [1]*count_matrix_2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(count_matrix_1)\n",
    "print(count_matrix_2)\n",
    "combined_matrix = count_matrix_1.append(count_matrix_2).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def NB(X, y):\n",
    "    normalized_X = normalize(X, axis=1)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size = 0.33)\n",
    "    \n",
    "    nb = GaussianNB()\n",
    "    nb.fit(X_train, y_train)\n",
    "    train_score = nb.score(X_train, y_train)\n",
    "    test_score = nb.score(X_test, y_test)\n",
    "\n",
    "    print(\"Training set score: %.3f\" % (train_score,))\n",
    "    print(\"Test set score: %.3f\" % (test_score, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NB(combined_matrix, genome_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
